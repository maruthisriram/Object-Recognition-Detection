{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing the libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\n%matplotlib inline\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nimport torch.optim as optim","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-30T14:37:31.555293Z","iopub.execute_input":"2022-03-30T14:37:31.555554Z","iopub.status.idle":"2022-03-30T14:37:31.567707Z","shell.execute_reply.started":"2022-03-30T14:37:31.555523Z","shell.execute_reply":"2022-03-30T14:37:31.566953Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"## Download the Dataset","metadata":{}},{"cell_type":"code","source":"tranform_train = transforms.Compose([transforms.Resize((227,227)), transforms.RandomHorizontalFlip(p=0.7), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\ntranform_test = transforms.Compose([transforms.Resize((227,227)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\ntorch.manual_seed(43)\ntrain_ds = CIFAR10(\"data/\", train=True, download=True, transform=tranform_train) \nval_size = 10000\ntrain_size = len(train_ds) - val_size\ntrain_ds, val_ds = random_split(train_ds, [train_size, val_size]) \ntest_ds = CIFAR10(\"data/\", train=False, download=True, transform=tranform_test) \n\ntrain_set = DataLoader(train_ds, batch_size=64, shuffle=True)\nval_set = DataLoader(val_ds, batch_size=64, shuffle=False)\ntest_set = DataLoader(test_ds, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:37:31.598327Z","iopub.execute_input":"2022-03-30T14:37:31.598813Z","iopub.status.idle":"2022-03-30T14:37:33.169613Z","shell.execute_reply.started":"2022-03-30T14:37:31.598785Z","shell.execute_reply":"2022-03-30T14:37:33.168861Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"## Define the CNN model with different activation function on which  we want to test the data set on","metadata":{}},{"cell_type":"markdown","source":"### Model with Relu as activation function","metadata":{}},{"cell_type":"code","source":"class model_1(nn.Module):\n    def __init__(self):\n        super(model_1, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 96, kernel_size= 11, stride=4, padding=0 )\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride= 1, padding= 2)\n        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride= 1, padding= 1)\n        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.fc1  = nn.Linear(in_features= 9216, out_features= 4096)\n        self.fc2  = nn.Linear(in_features= 4096, out_features= 10)\n\n\n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = self.maxpool(x)\n        x = F.relu(self.conv2(x))\n        x = self.maxpool(x)\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        x = self.maxpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:37:33.171118Z","iopub.execute_input":"2022-03-30T14:37:33.171834Z","iopub.status.idle":"2022-03-30T14:37:33.183662Z","shell.execute_reply.started":"2022-03-30T14:37:33.171796Z","shell.execute_reply":"2022-03-30T14:37:33.182739Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"### Model with tanh as Activation function","metadata":{}},{"cell_type":"code","source":"class model_2(nn.Module):\n    def __init__(self):\n        super(model_2, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 96, kernel_size= 11, stride=4, padding=0 )\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride= 1, padding= 2)\n        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride= 1, padding= 1)\n        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.fc1  = nn.Linear(in_features= 9216, out_features= 4096)\n        self.fc2  = nn.Linear(in_features= 4096, out_features= 10)\n\n\n    def forward(self,x):\n        x = F.tanh(self.conv1(x))\n        x = self.maxpool(x)\n        x = F.tanh(self.conv2(x))\n        x = self.maxpool(x)\n        x = F.tanh(self.conv3(x))\n        x = F.tanh(self.conv4(x))\n        x = F.tanh(self.conv5(x))\n        x = self.maxpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = F.tanh(self.fc1(x))\n        x = F.tanh(self.fc2(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:37:33.185134Z","iopub.execute_input":"2022-03-30T14:37:33.185472Z","iopub.status.idle":"2022-03-30T14:37:33.199552Z","shell.execute_reply.started":"2022-03-30T14:37:33.185437Z","shell.execute_reply":"2022-03-30T14:37:33.198763Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"### Model with sigmoid as activation function","metadata":{}},{"cell_type":"code","source":"class model_3(nn.Module):\n    def __init__(self):\n        super(model_3, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 96, kernel_size= 11, stride=4, padding=0 )\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride= 1, padding= 2)\n        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride= 1, padding= 1)\n        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.fc1  = nn.Linear(in_features= 9216, out_features= 4096)\n        self.fc2  = nn.Linear(in_features= 4096, out_features= 10)\n\n\n    def forward(self,x):\n        x = F.sigmoid(self.conv1(x))\n        x = self.maxpool(x)\n        x = F.sigmoid(self.conv2(x))\n        x = self.maxpool(x)\n        x = F.sigmoid(self.conv3(x))\n        x = F.sigmoid(self.conv4(x))\n        x = F.sigmoid(self.conv5(x))\n        x = self.maxpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = F.sigmoid(self.fc1(x))\n        x = F.sigmoid(self.fc2(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:37:33.201614Z","iopub.execute_input":"2022-03-30T14:37:33.202413Z","iopub.status.idle":"2022-03-30T14:37:33.214416Z","shell.execute_reply.started":"2022-03-30T14:37:33.202376Z","shell.execute_reply":"2022-03-30T14:37:33.213766Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"### Function to run the model","metadata":{}},{"cell_type":"code","source":"def runModel(model):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n    epoch_loss = []\n    model = model.to(device=device)\n    learning_rate = 0.01\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr= learning_rate,momentum = 0.85)\n\n    for epoch in range(15): \n        loss_ep = 0\n    \n        for batch_idx, (data, targets) in enumerate(train_set):\n            data = data.to(device=device)\n            targets = targets.to(device=device)\n            ## Forward Pass\n            optimizer.zero_grad()\n            scores = model(data)\n            loss = criterion(scores,targets)\n            loss.backward()\n            optimizer.step()\n            loss_ep += loss.item()\n\n        epoch_loss.append(loss_ep/len(train_set))\n        print(f\"Loss in epoch {epoch} is {loss_ep/len(train_set)}\")\n\n        with torch.no_grad():\n            num_correct = 0\n            num_samples = 0\n            for batch_idx, (data,targets) in enumerate(val_set):\n                data = data.to(device=device)\n                targets = targets.to(device=device)\n                ## Forward Pass\n                scores = model(data)\n                _, predictions = scores.max(1)\n                num_correct += (predictions == targets).sum()\n                num_samples += predictions.size(0)\n            print(\n                f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n\n            )\n    plt.plot(epoch_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:37:33.215789Z","iopub.execute_input":"2022-03-30T14:37:33.216066Z","iopub.status.idle":"2022-03-30T14:37:33.227892Z","shell.execute_reply.started":"2022-03-30T14:37:33.215993Z","shell.execute_reply":"2022-03-30T14:37:33.226950Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### Test the model","metadata":{}},{"cell_type":"code","source":"def testModel(model):\n    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n    correct_pred = {classname: 0 for classname in classes}\n    total_pred = {classname: 0 for classname in classes}\n    num_correct = 0\n    num_samples = 0\n    for batch_idx, (data,targets) in enumerate(test_set):\n        data = data.to(device=\"cuda\")\n        targets = targets.to(device=\"cuda\")\n        ## Forward Pass\n        scores = model(data)\n        _, predictions = scores.max(1)\n        for target, prediction in zip(targets,predictions):\n            if(target==prediction):\n                correct_pred[classes[target]]+=1\n            total_pred[classes[target]]+=1\n        num_correct += (predictions == targets).sum()\n        num_samples += predictions.size(0)\n    print(\n        f\"Accuracy =  {float(num_correct) / float(num_samples) * 100:.2f}\"\n    )\n\n\n    # print accuracy for each class\n    for classname, correct_count in correct_pred.items():\n        accuracy = 100 * float(correct_count) / total_pred[classname]\n        print(f'Accuracy for class  {classname:5s} = {accuracy:.1f} %')","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:37:33.229177Z","iopub.execute_input":"2022-03-30T14:37:33.229438Z","iopub.status.idle":"2022-03-30T14:37:33.240331Z","shell.execute_reply.started":"2022-03-30T14:37:33.229404Z","shell.execute_reply":"2022-03-30T14:37:33.239666Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"relu_model = model_1()\nrunModel(relu_model)\ntestModel(relu_model)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:37:33.241611Z","iopub.execute_input":"2022-03-30T14:37:33.242078Z","iopub.status.idle":"2022-03-30T14:39:48.071209Z","shell.execute_reply.started":"2022-03-30T14:37:33.242042Z","shell.execute_reply":"2022-03-30T14:39:48.070548Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"tanh_model = model_1()\nrunModel(tanh_model)\ntest_model(tanh_model)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:39:48.072328Z","iopub.execute_input":"2022-03-30T14:39:48.072646Z","iopub.status.idle":"2022-03-30T14:39:56.327690Z","shell.execute_reply.started":"2022-03-30T14:39:48.072608Z","shell.execute_reply":"2022-03-30T14:39:56.326593Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"sigmoid_model = model_1()\nrunModel(sigmoid_model)\ntest_model(sigmoid_model)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:39:56.328957Z","iopub.status.idle":"2022-03-30T14:39:56.329573Z","shell.execute_reply.started":"2022-03-30T14:39:56.329335Z","shell.execute_reply":"2022-03-30T14:39:56.329359Z"},"trusted":true},"execution_count":null,"outputs":[]}]}